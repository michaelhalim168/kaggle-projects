{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "for line in lines:\n",
    "    json_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for tweet in json_data:\n",
    "    tweet_data.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "def define_sentiment(text):\n",
    "    if ':(' in text and ':)' in text:\n",
    "        return 1 #Postive\n",
    "    elif ':(' in text:\n",
    "        return 0 #Negative\n",
    "    elif ':)' in text:\n",
    "        return 1 #Positive\n",
    "    else:\n",
    "        return 0 #Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    labels.append(define_sentiment(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "stopwords.extend(['RT'])\n",
    "\n",
    "import re\n",
    "pattern = '[^A-Za-z0-9]+'\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text.split() if word not in stopwords]\n",
    "\n",
    "def remove_punc(text):\n",
    "    return \" \".join([word for word in text if word not in punctuations])\n",
    "\n",
    "def convert_lowercase(text):\n",
    "    return ''.join([word.lower() for word in text])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    clean_text = re.sub('@.*?($| )','', text) \n",
    "    clean_text = re.sub('https.*?($| )', '', clean_text)\n",
    "    clean_text = re.sub(pattern, ' ', clean_text)\n",
    "    clean_text = re.sub(\"\\d+\", \"\", clean_text)\n",
    "    clean_text = re.sub(r'\\b\\w{1,2}\\b', '', clean_text)\n",
    "    clean_text = convert_lowercase(clean_text)\n",
    "    clean_text = remove_stopwords(clean_text)\n",
    "    clean_text = remove_punc(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_clean = []\n",
    "labels_clean = []\n",
    "\n",
    "for i in range(0, len(tweet_data)):\n",
    "    if preprocess_text(tweet_data[i]) == '':\n",
    "        pass\n",
    "    else:\n",
    "        tweet_data_clean.append(preprocess_text(tweet_data[i]))\n",
    "        labels_clean.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6825"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6825"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = tfidf.fit_transform(tweet_data_clean)\n",
    "tfidf_data = tfidf_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative comments: 3372\n",
      "Number of positive comments: 3374\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative comments:\", labels_clean.count(0))\n",
    "print(\"Number of positive comments:\", labels_clean.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, use_idf=True)\n",
    "tfidf_data = tfidf.fit_transform(tweet_data_clean)\n",
    "tfidf_data = tfidf_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, labels_clean, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6760398359695372\n",
      "Confusion Matrix: \n",
      " [[424 401]\n",
      " [152 730]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7492677211482133\n",
      "Confusion Matrix: \n",
      " [[593 232]\n",
      " [196 686]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7387229056824839\n",
      "Confusion Matrix: \n",
      " [[514 311]\n",
      " [135 747]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl-bootcamp",
   "language": "python",
   "name": "lhl-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
