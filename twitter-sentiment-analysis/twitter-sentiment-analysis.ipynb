{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "for line in lines:\n",
    "    json_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for tweet in json_data:\n",
    "    tweet_data.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "def define_sentiment(text):\n",
    "    if ':(' in text and ':)' in text:\n",
    "        return 1 #Postive\n",
    "    elif ':(' in text:\n",
    "        return 0 #Negative\n",
    "    elif ':)' in text:\n",
    "        return 1 #Positive\n",
    "    else:\n",
    "        return 0 #Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    labels.append(define_sentiment(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "stopwords.extend(['RT'])\n",
    "\n",
    "import re\n",
    "pattern = '[^A-Za-z0-9]+'\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text.split() if word not in stopwords]\n",
    "\n",
    "def remove_punc(text):\n",
    "    return \" \".join([word for word in text if word not in punctuations])\n",
    "\n",
    "def convert_lowercase(text):\n",
    "    return ''.join([word.lower() for word in text])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    clean_text = re.sub('@.*?($| )','', text) \n",
    "    clean_text = re.sub('https.*?($| )', '', clean_text)\n",
    "    clean_text = re.sub(pattern, ' ', clean_text)\n",
    "    clean_text = re.sub(\"\\d+\", \"\", clean_text)\n",
    "    clean_text = re.sub(r'\\b\\w{1,2}\\b', '', clean_text)\n",
    "    clean_text = convert_lowercase(clean_text)\n",
    "    clean_text = remove_stopwords(clean_text)\n",
    "    clean_text = remove_punc(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_clean = []\n",
    "labels_clean = []\n",
    "\n",
    "for i in range(0, len(tweet_data)):\n",
    "    if preprocess_text(tweet_data[i]) == '':\n",
    "        pass\n",
    "    else:\n",
    "        tweet_data_clean.append(preprocess_text(tweet_data[i]))\n",
    "        labels_clean.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6825"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = tfidf.fit_transform(tweet_data_clean)\n",
    "#tfidf_data = tfidf_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative comments: 3410\n",
      "Number of positive comments: 3415\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative comments:\", labels_clean.count(0))\n",
    "print(\"Number of positive comments:\", labels_clean.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, use_idf=True)\n",
    "tfidf_data = tfidf.fit_transform(tweet_data_clean)\n",
    "tfidf_data = tfidf_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, labels_clean, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7065026362038664\n",
      "Precision: 0.6727107887579329\n",
      "Recall Score: 0.8412698412698413\n",
      "ROC-AUC-Score: 0.7018470418470419\n",
      "Confusion Matrix: \n",
      " [[464 361]\n",
      " [140 742]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('ROC-AUC-Score:', roc_auc_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7539543057996485\n",
      "Precision: 0.7583892617449665\n",
      "Recall Score: 0.7687074829931972\n",
      "ROC-AUC-Score: 0.7534446505875076\n",
      "Confusion Matrix: \n",
      " [[609 216]\n",
      " [204 678]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('ROC-AUC-Score:', roc_auc_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7586408904510837\n",
      "Precision: 0.7225378787878788\n",
      "Recall Score: 0.8650793650793651\n",
      "ROC-AUC-Score: 0.754963924963925\n",
      "Confusion Matrix: \n",
      " [[532 293]\n",
      " [119 763]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('ROC-AUC-Score:', roc_auc_score(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl-bootcamp",
   "language": "python",
   "name": "lhl-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
